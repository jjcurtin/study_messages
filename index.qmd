---
title: Using Cellular Communication Sensing to Support Early Recovery from Alcohol Use Disorder
author:
  - name: Kendra Wyant
    email: kpaquette2@wisc.edu
    orcid: 0000-0002-0767-7589
    corresponding: false
    #roles: []
    affiliations:
    - Department of Psychology, University of Wisconsin-Madison
  - name: Coco Yu
    email: jyu274@wisc.edu
    orcid: 0000-0002-7731-0563
    corresponding: false
    #roles: []
    affiliations:
    - Department of Psychology, University of Wisconsin-Madison
  - name: John J. Curtin 
    orcid: 0000-0002-3286-938X
    corresponding: true
    email: jjcurtin@wisc.edu
    #roles:
      #- Project administration
      #- Software
      #- Visualization
    affiliations:
    - Department of Psychology, University of Wisconsin-Madison
keywords:
  - Substance use disorders
  - Machine learning
  - Cellular Sensing
abstract: |

#plain-language-summary: |
  #To be filled in.
#key-points:
  #- Take away point 1 
  #- Take away point 2
date: last-modified
citeproc: true
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl
bibliography: messages.bib
#citation:
  #container-title: To be filled in. 
number-sections: false 
tbl-cap-location: bottom
editor_options: 
  chunk_output_type: console
---

<!--
Target Journal: JMIR Formative Research (1500 words)

Goal word counts: 

- Introduction: 350 words (currently 366 words)
- Methods: 600 words (currently 614 words)
- Results: 200 words (currently 194)
- Discussion: 350 words
-->

```{r}
#| echo: false
#| message: false

library(tidyverse)
suppressPackageStartupMessages(source("https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true"))

path_models <- format_path("risk/models/messages")

pp_perf <- read_csv(here::here(path_models, "pp_perf_tibble.csv"),
                    show_col_types = FALSE)

contrast <- read_csv(here::here(path_models, 
                                "contrast_baseline.csv"),
                    show_col_types = FALSE)
```


# Introduction

Alcohol Use Disorder (AUD) is a chronic, relapsing disease [@mclellanDrugDependenceChronic2000;@dennisManagingAddictionChronic2007; @rounsavilleLapseRelapseChasing2010]. Lapses, single episodes of alcohol use, and relapse, a full return to harmful drinking, can occur at any point in recovery [@scottPathwaysRelapseTreatment2005;@nguyenPredictingRelapseAlcohol2020a; @witkiewitzPredictorsHeavyDrinking2011; @kirshenbaumQuantitativeReviewUbiquitous2009]. As with other chronic health conditions where symptoms fluctuate, sometimes unexpectedly, sustained AUD recovery requires ongoing monitoring of lapse risk.

Machine learning–guided recovery systems may now assist with the inherently difficult task of identifying when and why someone is at increased risk. Personal sensing of densely sampled data from individuals' day-to-day lives can provide the inputs necessary for temporally dynamic lapse predictions [@mohrPersonalSensingUnderstanding2017]. Early models using ecological momentary assessment data have achieved excellent accuracy [@chihPredictiveModelingAddiction2014; @wyantMachineLearningModels2024; @wyantForecastingRiskAlcoholunderreview]. Still, questions remain about the long-term feasibility of self-report sensing methods and whether new, important risk factors might emerge from sensing methods that passively collect smartphone data without user input.

Cellular communication sensing may be one promising method. It offers the potential for greater temporal specificity in capturing fluctuations in risk compared with self-report data. Collecting communication data in near real time could allow an algorithm to detect potential triggers as they occur, without prompting users to reflect on their feelings or waiting for users to report about their environement at a later point. For example, late night phone calls could indicate an emergency, "drunk dialing", or other risk-relevant interactions, while an expanding or shrinking social circle could be characterized by the number of unique contacts someone has communicated with.

These data may become even more powerful when communication contacts are contextualized with personal meaning for a given participant (e.g., Who is this contact to them? How pleasant or unpleasant is a typical interaction with them? Have they drank with them in the past?). In this scenario, contextualized communication logs might reveal that the late-night phone call was to a sponsor, or that the shrinking social circle was due to reduced contact with people who are unsupportive of their recovery.

In this study, we evaluated the performance of a machine learning model that predicts the probability of a next-day lapse using contextualized cellular communication data. We also describe the most important features contributing to these predictions, with the goal of identifying new, clinically meaningful features emerging from communication-based sensing.


# Methods

## Participants and Procedure
We recruited adults in early recovery from AUD in Madison, Wisconsin, through print and digital advertisements and partnerships with treatment centers. Eligibility criteria required that participants were age 18 or older, able to read and write in English, had moderate to severe AUD ^[(≥4 self-reported DSM-5 symptoms)], had been abstinent from alcohol for 1–8 weeks, were willing to use a single smartphone, and were not exhibiting severe psychosis or paranoia.^[Defined as scores >2.2 or 2.8, respectively, on the psychosis or paranoia scales of the Symptom Checklist–90 [@derogatislBriefSymptomInventory].]

Participants completed up to 5 study visits over approximately 3 months: a screening visit, intake visit, and 3 monthly follow-up visits. At screening we collected demographic information (age, sex at birth, race, ethnicity, education, marital status, employment, and income) and clinical characteristics (DSM-5 AUD symptom count, alcohol problems [@hurlbutAssessingAlcoholProblems1992], and presence of psychological symptoms [@derogatislBriefSymptomInventory]). At intake we collected additional self-report data on abstinence self-efficacy [@mckiernanDevelopmentBriefAbstinence2011], craving [@flanneryPsychometricPropertiesPenn1999], and recent recovery efforts. At each monthly follow-up, we downloaded cellular communication metadata (voice calls and SMS text message logs) from participants' smartphones. We identified important contacts (i.e., individuals they had communicated with at least twice by call or text in the past month) and asked 7 contextual questions about these contacts.

While enrolled, participants completed 4 brief daily ecological momentary assessments (7-10 questions). The first item assessed alcohol use (date and time of any unreported drinking episodes). Lapse reports were verified at follow-up visits using a timeline follow-back interview. Additional sensing data streams and self-report measures were collected for the parent grant. The full study protocol is available on our Open Science Framework page ([https://osf.io/wgpz9/](https://osf.io/wgpz9/)). 

We screened 192 participants. Of these, 169 enrolled and 154 completed the first follow-up. Data from 10 participants were excluded due to loss of abstinence goals, careless responding, or unusually low compliance. The final analytic sample included 144 participants.


## Data Analysis Plan
Our models predicted the probability of an alcohol lapse within a 24-hour window. Predictions were generated daily at 4 a.m., beginning on participants' second study day and continuing for up to 3 months. In total, there were 11,507 labeled prediction windows across all participants. 

Features were engineered from all available data up to the start of each window.^[We filtered the data to include only communications with known context prior to feature engineering.] The full model included 406 features from cellular communication data plus 24 features from baseline self-report measures. We also evaluated a comparison model that used only the baseline features. @tbl-1 details the raw predictors and feature engineering procedures. 

Candidate model configurations differed by algorithm (elastic net, random forest, XGBoost), outcome resampling method, and hyperparameter values. The best configuration for each model was selected using 6 repeats of participant-grouped 5-fold cross-validation. Our performance metric was area under the receiver operating curve (auROC). Folds were stratified by a between-subject measure of our outcome (low lapsers: 0-9 lapses; high lapsers: 10+ lapses).   

We evaluated model performance with a Bayesian hierarchical generalized linear model. Posterior distributions with 95% credible intervals (CI) were estimated from the 30 held-out test sets using weakly informative, data-dependent priors to regularize and reduce overfitting.^[Residual SD ~ normal(0, exp(2)); intercept (centered predictors) ~ normal(2.3, 1.3); window-width contrasts ~ normal(0, 2.69); covariance ~ decov(1,1,1,1).] Random intercepts were included for repeat and fold (nested within repeat). auROCs were logit-transformed and regressed on model type to estimate the probability that model performances differed systematically. 

Our best performing models used an elastic net algorithm. We quantified feature importance by examining the retained features (i.e., coefficient value > 0) in the full model and ordering them by absolute coefficient value. These values provide an estimate of the direction and magnitude of association between each predictor and the outcome, conditional on the other features retained. All our annotated analysis scripts are publicly available on our study website ([https://jjcurtin.github.io/study_messages/](https://jjcurtin.github.io/study_messages/)).

{{< embed notebooks/mak_tables.qmd#tbl-1 >}} 


## Ethical Considerations
All procedures were approved by the University of Wisconsin-Madison Institutional Review Board (Study #2015-0780). All participants provided written informed consent.


# Results

## Participants
@tbl-2 provides the demographic characterization of our sample. We obtained a total of 375,912 contextualized communications across participants. Participants had, on average, 2,610 communications (range = 109-14,225). 56% of participants reported at least one lapse. 

{{< embed notebooks/mak_tables.qmd#tbl-2 >}} 

## Model Evaluation
The median posterior auROC for the full model was `r round(subset(pp_perf, model == "full model")$pp_median, 2)`, with relatively narrow 95% CI ([`r round(subset(pp_perf, model == "full model")$pp_lower, 2)`, `r round(subset(pp_perf, model == "full model")$pp_upper, 2)`]) that did not contain .5. This provides strong evidence that the model is capturing signal in the data. The final model retained 13 features (@fig-1). The top four were baseline measures of abstinence confidence, having a goal of abstinence, abstinence self-efficacy when experiencing negative affect, and craving. Communication frequency with people unaware of the individual's recovery goals also emerged as an important feature associated with increased lapse risk.

We evaluated a comparison model to assess the incremental predictive value of cellular communication features beyond baseline measures. The baseline model retained 5 features and achieved performance nearly identical to the full model (median auROC = `r round(subset(pp_perf, model == "baseline model")$pp_median, 2)`, 95% CI [`r round(subset(pp_perf, model == "baseline model")$pp_lower, 2)`, `r round(subset(pp_perf, model == "baseline model")$pp_upper, 2)`]). The median difference in auROC between the full and baseline models was less than .01, providing no evidence (52% probability) that their posterior distributions were meaningfully different.

<!-- Retained communication features:
Interesting they are all over the longer period durations - features become more meaningful with more data?

p168.l0.dratecount.phone_number,
p72.l0.rratecount.drink_status.NonDrinker,
p168.l0.rratecount.drink_status.Drinker,
p168.l0.rratecount.support_status.Dont Know,
p168.l0.rratecount.contact_experience.Unpleasant,
p168.l0.rratecount.cont_type.friend   
-->

{{< embed notebooks/mak_figures.qmd#fig-1 >}} 




# Discussion






\newpage
