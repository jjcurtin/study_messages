---
title: Using Cellular Communication Sensing to Support Early Recovery from Alcohol Use Disorder
author:
  - name: Kendra Wyant
    email: kpaquette2@wisc.edu
    orcid: 0000-0002-0767-7589
    corresponding: false
    #roles: []
    affiliations:
    - Department of Psychology, University of Wisconsin-Madison
  - name: Coco Yu
    email: jyu274@wisc.edu
    orcid: 0000-0002-7731-0563
    corresponding: false
    #roles: []
    affiliations:
    - Department of Psychology, University of Wisconsin-Madison
  - name: John J. Curtin 
    orcid: 0000-0002-3286-938X
    corresponding: true
    email: jjcurtin@wisc.edu
    #roles:
      #- Project administration
      #- Software
      #- Visualization
    affiliations:
    - Department of Psychology, University of Wisconsin-Madison
keywords:
  - Substance use disorders
  - Machine learning
  - Cellular Sensing
abstract: |

#plain-language-summary: |
  #To be filled in.
#key-points:
  #- Take away point 1 
  #- Take away point 2
date: last-modified
citeproc: true
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl
bibliography: messages.bib
#citation:
  #container-title: To be filled in. 
number-sections: false 
tbl-cap-location: bottom
editor_options: 
  chunk_output_type: console
---

<!--
Target Journal: JMIR Formative Research (1500 words)

Goal word counts: 

- Introduction: 400 words
- Methods: 500 words
- Results: 300 words
- Discussion: 500 words
-->

# Introduction

One of the biggest challenges in Alcohol Use Disorders (AUD) treatment stems from the chronic relapsing nature of this disease [@scottPathwaysRelapseTreatment2005]. People can relapse days, weeks, and even years after obtaining the goal of abstinence. At least 60% of AUD patients relapse to heavy drinking within 6 months following treatment [@nguyenPredictingRelapseAlcohol2020a; @witkiewitzPredictorsHeavyDrinking2011a; @kirshenbaumQuantitativeReviewUbiquitous2009].
At most 50% of people with an AUD achieve remission after several years [@fleuryRemissionSubstanceUse2016; @heymanQuittingDrugsQuantitative2013].

Identifying initial lapses in early recovery is critical. Lapses -- single episodes of alcohol use -- are easy to define, have a clear onset, and are also clinically meaningful. They serve as an early warning sign of returning back to previous drinking behavior inconsistent with desired goals [@witkiewitzRelapsePreventionAlcohol2004a; @chungRelapseAlcoholOther2006a; @marlattRelapsePreventionMaintenance2005a]. Lapse predicts future lapses, with more frequent ones resulting in increased risks of relapse [@hogstrombrandtPredictionSingleEpisodes1999a; @witkiewitzRelapsePreventionAlcohol2004a].

Current predictions of alcohol lapses rely heavily on self reports, which can be burdensome to measure in long run. Machine learning models leveraging ecological momentary assessment (EMA) measures have performed relatively well to predict goal-inconsistent alcohol use [@wyantMachineLearningModels2024]. The surveys were collected up to four times daily for three months. However, constantly completing surveys makes it burdensome for AUD patients. Although most EMA relevant mental health research demonstrated modest compliance rates, their time windows last from two weeks to three months [@porras-segoviaSmartphonebasedEcologicalMomentary2020; @czyzEcologicalAssessmentDaily2018; @vangenugtenExperiencedBurdenAdherence2020; @mackesy-amitiFeasibilityEcologicalMomentary2018; @hungSmartphonebasedEcologicalMomentary2016]. The study length is insufficient because AUD is a chronic disease that requires constant risk monitoring. As extended period of time is anticipated, users' perceived burden of answering surveys is presumably larger [@mogkImplementationWorkflowStrategies2023]. Although minimizing the number of items in the surveys and the frequency of prompting users to complete the surveys might help mitigate the associated burden, it can inevitably reduce the prediction precision and temporal precision of predictions.

Passive cellular communication sensing represents new opportunities due to its feasibility, relatively low burden on individuals and continuous data collection. In a smartphone-based sensing platform the primary expense on the individual is the smartphone. Smartphone usage is already widespread. Eighty-five percent of US adults have a smartphone and this number is consistent across all sociodemographic groups, including those in recovery programs for substance use [@massonHealthrelatedInternetUse2019a; @pewresearchcenterMobileFactSheet2021a]. Studies collecting passive data have demonstrated high acceptability from participants and higher compliance rates compared to active measures [@wyantAcceptabilityPersonalSensing2023a; @beukenhorstUsingSmartphonesReduce2022a]. Further, risk monitoring using cellular sensing is temporally sensitive to fluctuating risks. Analyzing communication patterns can detect potential triggers in time without actively prompting users to reflect on their feelings at the moment or report their environment.

Cellular communications, with minimal contextual information, is embedded with potentially rich information that align with relapse antecedents. For example, social interactions can have important influences on drinking behavior [@hunter-reelEmphasizingInterpersonalFactors2009a; @alvarezSocialNetworkHeavy2021a]. We may be able to capture immediate risk based on who someone is calling or what time of day it is. Decreased interactions may signify isolation common with depressive symptoms, reaching out to people in one’s social network could signify a positive coping strategy, or changes in patterns between a single person in one’s social network could indicate conflict [@millerHowEffectiveAlcoholism2001a; @huffordRelapseNonlinearDynamic2003a; @chihPredictiveModelingAddiction2014a].

This study aims at building machine learning models from cellular communications that identify *who* are at heightened risk for alcohol lapses, *when* they will lapse, and *why* they are at increased risk.

# Methods

## Participants and Procedure
We recruited adults in early recovery from AUD in Madison, Wisconsin, via print and digital advertisements and treatment center partnerships. We required participants: were age 18 or older, could write and read in English, had moderate to severe AUD ^[(\>= 4 self-reported DSM-5 symptoms)], were abstinent from alcohol for 1-8 weeks, were willing to use a single smartphone, and were not exhibiting severe symptoms of psychosis or paranoia.^[Defined as scores >2.2 or 2.8, respectively, on the psychosis or paranoia scales of the Symptom Checklist–90 [@derogatislBriefSymptomInventory]]

Participants completed up to 5 study visits over approximately 3 months: a screening visit, intake visit, and 3 monthly follow-up visits. At screening we collected self-report information about demographics (age, sex at birth, race, ethnicity, education, marital status, employment, and income) and clinical characteristics (DSM-5 AUD symptom count, alcohol problems [@hurlbutAssessingAlcoholProblems1992], and presence of psychological symptoms [@derogatislBriefSymptomInventory]). At intake we collected self-report information about abstinence self-efficacy [@mckiernanDevelopmentBriefAbstinence2011], craving [@flanneryPsychometricPropertiesPenn1999], and recent alcohol recovery efforts. At each monthly follow-up visit, we downloaded participants' cellular communications (voice call and SMS text message metadata logs) from their smartphone devices. Participants were asked 7 contextual questions about important contacts (i.e., people whom the partcipant communicated with at least twice by voice call or SMS text message in a one month period). While enrolled, participants were expected to complete 4 brief (7-10 questions) daily ecological momentary assessments (EMA). The first item asked participants to report dates and times of any recent alcohol use. We verified lapse reports at follow-up visits with a timeline follow-back interview. Additional sensing data streams and self-report measures were collected as part of the parent grant's aims (R01 AA024391). Our full study protocol and all measures are publicly available ([https://osf.io/wgpz9/](https://osf.io/wgpz9/)). 

We screened 192 participants. Of these, 169 enrolled and 154 completed the first follow-up visit. We excluded data from 10 participants for no longer having a goal of abstinence, evidence of careless responding, and unusually low compliance. Our final sample included 144 participants. 


## Data Analysis Plan
Our models predicted probability of a lapse (i.e., alcohol use) in a 24-hour prediction window. Predictions were made at 4 am each day for up to 3 months. This produced a total of 11,507 labeled prediction timepoints across all participants. Features were engineered using all available data up until the prediction timepoint^[We filtered down the data to only include communications with important contacts (i.e., communications we had contextual information about) prior to feature engineering.]. @tbl-1 presents the raw predictors and engineered features included in each model. The full model uses all available features derived from baseline self-report measures (24 features) and cellular communication data (406 features). The baseline model uses only features collected via self-report at baseline. 

Candidate model configurations differed by statistical algorithm (elastic net, random forest, XGBoost), outcome resampling method, and hyperparemter values. The best model configuration for the full model and baseline model were selected and evaluated using 6 repeats of participant-grouped 5-fold cross-validation. Folds were stratified on a between-subject measure of our outcome (low lapsers/0-9 lapses vs. and high lapsers/10+ lapses).   

We used a Bayesian hierarchical generalized linear model to estimate the posterior probability distributions and 95% Bayesian credible intervals (CIs) from the 30 held-out test sets for our two best models. We used weakly informative, data-dependent priors that take into account the order of magnitude of the variables to provide some regularization to stabilize computation and avoid over-fitting.^[Priors were set as follows: residual standard deviation ~ normal(location=0, scale=exp(2)), intercept (after centering predictors) ~ normal(location=2.3, scale=1.3), the two coefficients for window width contrasts ~ normal (location=0, scale=2.69), and covariance ~ decov(regularization=1, concentration=1, shape=1, scale=1).] We set two random intercepts to account for our resampling method: one for the repeat, and another for the fold nested within repeat. auROCs were transformed using the logit function and regressed as a function of model to determine the probability that the models’ performances differed systematically from each other. 

- Feature Importance

Our annotated analysis scripts are publicly available on our study website ([https://jjcurtin.github.io/study_messages/](https://jjcurtin.github.io/study_messages/)).


<!--Table 1: create table of all features and which models they were in-->

## Ethical Considerations
All procedures were approved by the University of Wisconsin-Madison Institutional Review Board (Study #2015-0780). All participants provided written informed consent.


# Results

## Participants
@tbl-2 provides the demographic characterization of our sample. We obtained a total of 375,912 contextualized communications across participants. Participants had, on average, 2,610 communications (range = 109-14,225). 56% of participants reported at least one lapse. 

{{< embed notebooks/mak_tables.qmd#tbl-2 >}} 

## Model Evaluation


{{< embed notebooks/mak_figures.qmd#fig-1 >}} 





# Discussion






\newpage
