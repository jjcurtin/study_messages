---
title: Evaluating Cellular Communication Sensing for Lapse Risk Prediction During Early Recovery from Alcohol Use Disorder
author:
  - name: Kendra Wyant
    email: kpaquette2@wisc.edu
    orcid: 0000-0002-0767-7589
    corresponding: false
    #roles: []
    affiliations:
    - Department of Psychology, University of Wisconsin-Madison
  - name: Coco Yu
    email: jyu274@wisc.edu
    orcid: 0000-0002-7731-0563
    corresponding: false
    #roles: []
    affiliations:
    - Department of Psychology, University of Wisconsin-Madison
  - name: John J. Curtin 
    orcid: 0000-0002-3286-938X
    corresponding: true
    email: jjcurtin@wisc.edu
    #roles:
      #- Project administration
      #- Software
      #- Visualization
    affiliations:
    - Department of Psychology, University of Wisconsin-Madison
keywords:
  - Substance use disorders
  - Machine learning
  - Cellular Sensing
abstract: |
#plain-language-summary: |
  #To be filled in.
#key-points:
  #- Take away point 1 
  #- Take away point 2
date: last-modified
citeproc: true
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl
bibliography: messages.bib
#citation:
  #container-title: To be filled in. 
number-sections: false 
tbl-cap-location: bottom
editor_options: 
  chunk_output_type: console
---

<!--
Target Journal: JMIR Formative Research (1500 words)

Goal word counts: 

- Introduction: 350 words (currently 364 words)
- Methods: 600 words (currently 613 words)
- Results: 200 words (currently 194)
- Discussion: 350 words (currently 383)

total: 1554 words
-->

```{r}
#| echo: false
#| message: false

library(tidyverse)
suppressPackageStartupMessages(source("https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true"))

path_models <- format_path("risk/models/messages")

pp_perf <- read_csv(here::here(path_models, "pp_perf_tibble.csv"),
                    show_col_types = FALSE)

contrast <- read_csv(here::here(path_models, 
                                "contrast_baseline.csv"),
                    show_col_types = FALSE)
```


# Introduction

Alcohol Use Disorder (AUD) is a chronic, relapsing disease [@mclellanDrugDependenceChronic2000;@dennisManagingAddictionChronic2007; @rounsavilleLapseRelapseChasing2010]. Lapses, single episodes of alcohol use, are among the strongest predictors (and a necessary precursor) for relapse, a full return to harmful drinking [@marlattRelapsePreventionMaintenance1985; @marlattRelapsePreventionSecond2007]. While lapses can occur at any point in recovery, they are particularly risky during early recovery [@daleyReducingRiskRelapse2019]. Protective coping mechanisms and socio-environmental resources that support recovery are dynamic and accumulate over time [@clevelandRecoveryRecoveryCapital2021]. As a result, early recovery represents a critical window of vulnerability during which a lapse is more likely to escalate into relapse.

An automated recovery support system powered by personal sensing and machine learning may assist with the inherently difficult task of identifying when and why someone is at increased risk for lapse. Personal sensing of densely sampled data from individuals' day-to-day lives can provide the inputs necessary for temporally dynamic lapse predictions [@mohrPersonalSensingUnderstanding2017]. Early machine learning models using ecological momentary assessment data have achieved excellent accuracy [@chihPredictiveModelingAddiction2014; @wyantMachineLearningModels2024; @wyantForecastingRiskAlcoholunderreview]. Still, questions remain about the long-term feasibility of self-report sensing methods and whether new, important risk factors might emerge from sensing methods that passively collect smartphone data without user input.

Cellular communication sensing may be one promising method. It offers the potential for greater temporal specificity in capturing fluctuations in risk compared with self-report data (e.g., as they occur vs. prompting users to make reports the next day). Late night phonecalls could indicate an emergency, "drunk dialing", or other risk-relevant interactions. Cellular communications can also capture risk-relevant constructs more difficult for people to self report. A change in the number of unique contacts someone is interacting with could indicate an expanding or shrinking social circle.

These passive data may become even more powerful when communications are contextualized with personal meaning for a given participant (e.g., Who is this contact to them? What is a typical interaction with them like?). In the above examples, contextualized communication data might reveal that the late-night phone call was to a sponsor, or that the shrinking social circle was due to reduced contact with people who are unsupportive of their recovery.

In this study, we evaluated the performance of a machine learning model that predicts the probability of a next-day alcohol lapse amobg individuals in early recovery from alcohol use disorder using contextualized cellular communication data. We also describe the most important features contributing to these predictions, with the goal of identifying new, clinically meaningful features emerging from communication-based sensing.


# Methods

## Participants and Procedure
We recruited adults in early recovery from AUD in Madison, Wisconsin, through print and digital advertisements and partnerships with treatment centers. Eligibility criteria required that participants were age 18 or older, able to read and write in English, had moderate to severe AUD ^[(≥4 self-reported DSM-5 symptoms)], had been abstinent from alcohol for 1–8 weeks, were willing to use a single smartphone, and were not exhibiting severe psychosis or paranoia.^[Defined as scores >2.2 or 2.8, respectively, on the psychosis or paranoia scales of the Symptom Checklist–90 [@derogatislBriefSymptomInventory].]

Participants completed up to 5 study visits over approximately 3 months: a screening visit, intake visit, and 3 monthly follow-up visits. At screening we collected demographic information (age, sex at birth, race, ethnicity, education, marital status, employment, and income) and clinical characteristics (DSM-5 AUD symptom count, alcohol problems [@hurlbutAssessingAlcoholProblems1992], and presence of psychological symptoms [@derogatislBriefSymptomInventory]). At intake we collected additional self-report data on abstinence self-efficacy [@mckiernanDevelopmentBriefAbstinence2011], craving [@flanneryPsychometricPropertiesPenn1999], and recent recovery efforts. At each monthly follow-up, we downloaded cellular communication metadata (voice calls and SMS text message logs) from participants' smartphones. We identified important contacts (i.e., individuals they had communicated with at least twice by call or text in the past month) and asked 7 contextual questions about these contacts.

While enrolled, participants completed 4 brief daily ecological momentary assessments (7-10 questions). The first item assessed alcohol use (date and time of any unreported drinking episodes). Lapse reports were verified at follow-up visits using a timeline follow-back interview. Additional sensing data streams and self-report measures were collected for the parent grant. The full study protocol is available on our Open Science Framework page ([https://osf.io/wgpz9/](https://osf.io/wgpz9/)). 

We screened 192 participants. Of these, 169 enrolled and 154 completed the first follow-up. Data from 10 participants were excluded due to loss of abstinence goals, careless responding, or unusually low compliance. The final analytic sample included 144 participants.


## Data Analysis Plan
Our models predicted the probability of an alcohol lapse within a 24-hour window. Predictions were generated daily at 4 a.m., beginning on participants' second study day and continuing for up to 3 months. In total, there were 11,507 labeled prediction windows across all participants. 

Features were engineered from all available data up to the start of each window.^[We filtered the data to include only communications with known context prior to feature engineering.] The full model included 406 features from cellular communication data plus 24 features from baseline self-report measures. We also evaluated a comparison model that used only the baseline features. @tbl-1 details the raw predictors and feature engineering procedures. 

Candidate model configurations differed by algorithm (elastic net, random forest, XGBoost), outcome resampling method, and hyperparameter values. The best configuration for each model was selected using 6 repeats of participant-grouped 5-fold cross-validation. Our performance metric was area under the receiver operating curve (auROC). Folds were stratified by a between-subject measure of our outcome (low lapsers: 0-9 lapses; high lapsers: 10+ lapses).   

We evaluated model performance with a Bayesian hierarchical generalized linear model. Posterior distributions with 95% credible intervals (CI) were estimated from the 30 held-out test sets using weakly informative, data-dependent priors to regularize and reduce overfitting.^[Residual SD ~ normal(0, exp(2)); intercept (centered predictors) ~ normal(2.3, 1.3); window-width contrasts ~ normal(0, 2.69); covariance ~ decov(1,1,1,1).] Random intercepts were included for repeat and fold (nested within repeat). auROCs were logit-transformed and regressed on model type to estimate the probability that model performances differed systematically. 

Our best performing models used an elastic net algorithm. We quantified feature importance by examining the retained features (i.e., coefficient value > 0) in the full model and ordering them by absolute coefficient value. These values provide an estimate of the direction and magnitude of association between each predictor and the outcome, conditional on the other features retained. All our annotated analysis scripts are publicly available on our study website ([https://jjcurtin.github.io/study_messages/](https://jjcurtin.github.io/study_messages/)).

{{< embed notebooks/mak_tables.qmd#tbl-1 >}} 

<!--Coco: It feels a little weird to have the last two columns. How about separating the tables so that we have one for baseline-only and one for additional communication features?-->

## Ethical Considerations
All procedures were approved by the University of Wisconsin-Madison Institutional Review Board (Study #2015-0780). All participants provided written informed consent.


# Results

## Participants
@tbl-2 provides the demographic characterization of our sample. We obtained a total of 375,912 contextualized communications across participants. Participants had, on average, 2,610 communications (range = 109-14,225). 56% of participants reported at least one lapse. 

{{< embed notebooks/mak_tables.qmd#tbl-2 >}} 

## Model Evaluation
The median posterior auROC for the full model was `r round(subset(pp_perf, model == "full model")$pp_median, 2)`, with relatively narrow 95% CI ([`r round(subset(pp_perf, model == "full model")$pp_lower, 2)`, `r round(subset(pp_perf, model == "full model")$pp_upper, 2)`]) that did not contain .5. This provides strong evidence that the model is capturing signal in the data. The final model retained 13 features (@fig-1). The top four were baseline measures of abstinence confidence, having a goal of abstinence, abstinence self-efficacy when experiencing negative affect, and craving. Communication frequency with people unaware of the individual's recovery goals also emerged as an important feature associated with increased lapse risk.

We evaluated a comparison model to assess the incremental predictive value of cellular communication features beyond baseline measures. The baseline model retained 5 features and achieved performance nearly identical to the full model (median auROC = `r round(subset(pp_perf, model == "baseline model")$pp_median, 2)`, 95% CI [`r round(subset(pp_perf, model == "baseline model")$pp_lower, 2)`, `r round(subset(pp_perf, model == "baseline model")$pp_upper, 2)`]). The median difference in auROC between the full and baseline models was less than .01, providing no evidence (52% probability) that their posterior distributions were meaningfully different.

<!-- Retained communication features:
Interesting they are all over the longer period durations - features become more meaningful with more data?

p168.l0.dratecount.phone_number,
p72.l0.rratecount.drink_status.NonDrinker,
p168.l0.rratecount.drink_status.Drinker,
p168.l0.rratecount.support_status.Dont Know,
p168.l0.rratecount.contact_experience.Unpleasant,
p168.l0.rratecount.cont_type.friend   
-->

{{< embed notebooks/mak_figures.qmd#fig-1 >}} 




# Discussion

Our model achieved fair performance, with an auROC of `r round(subset(pp_perf, model == "full model")$pp_median, 2)`, indicating that some predictive signal was present. However, it did not offer incremental value beyond a baseline model that included only demographic and self-report measures. Consistent with this, the four most important predictors in our model were all self-report variables: abstinence confidence, abstinence goal, negative affect efficacy, and craving. 

Nonetheless, several communication features were retained in the final model with moderately sized coefficients. These included communications with people unaware of the participant's recovery status, non-drinkers, friends, and individuals who were unpleasant to interact with. In contrast, raw counts of calls and text messages and call durations were not retained in the final model. This implies that the quantity of communication may be less informative than the quality and social significance. Future research may benefit from collecting richer contextual data about communication contacts to better understand the social dynamics contributing to lapse risk. 

Even with highly contextualized communication data, however, prediction may be limited by data sparsity. Many participants had few daily communications, and some had extended periods with no recorded interactions at all. Our study design may have further contributed to this limitation. We collected only phone and SMS text communications through the native smartphone app. In recent years, many individuals use private messaging apps (e.g., WhatsApp, Signal) or social media platforms (e.g., Facebook Messenger, Instagram) as their primary communication method [@mcdowellPreferencesAttitudesDigital2025]. Therefore, our dataset likely missed a substantial portion of participants' communications. Future studies could explore whether data from these platforms yield stronger predictive signals.

We cannot entirely dismiss the potential value of cellular communication data for risk prediction. For example, researchers have successfully incorporated communication data into models with other sensing data (e.g., accelerometer, geolocation, and device usage) to predict alcohol use episodes [@baeDetectingDrinkingEpisodes2017; @baeLeveragingMobilePhone2023]. However, even in these instances, the contribution of cellular communications is questionable and other sensing methods like geolocation appear to be more promising. Other practical challenges for collecting call and text message data further limit the feasibility of this sensing method (e.g., Apple heavily restricts the collection of these data by apps in their app store). We conclude that other forms of social interaction characterization (e.g., engineering time spent with supportive contacts from geolocation data) are more worthwhile to pursue in future research.



\newpage
