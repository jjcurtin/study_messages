{
  "hash": "139e82bc6754d4b473b18f92284b82a6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Model evaluation\"\nauthor: \"Kendra Wyant\"\ndate: \"2025-10-01\"\noutput: \n  html_document:\n    toc: true \n    toc_depth: 4\nformat:\n  html:\n    embed-resources: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n### Set Up Environment\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(source(\"https://github.com/jjcurtin/lab_support/blob/main/format_path.R?raw=true\"))\nsuppressPackageStartupMessages(library(tidyposterior))\n\npath_models <- format_path(str_c(\"risk/models/messages\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ntest_metrics_full <- read_csv(here::here(path_models, \n                                         \"best_config_v17_kfold_full.csv\"), \n                              show_col_types = FALSE) |> \n  select(split_num, \"full model\" = roc_auc) |> \n  arrange(split_num)\n\ntest_metrics_baseline <- read_csv(here::here(path_models, \n                                  \"best_config_v17_kfold_baseline.csv\"),\n                                  show_col_types = FALSE) |> \n  select(split_num, \"baseline model\" = roc_auc) |> \n  arrange(split_num)\n\n# test_metrics_meta <- read_csv(here::here(path_models, \n#                                        \"best_config_v17_kfold_meta.csv\"),\n#                             show_col_types = FALSE) |> \n#   select(split_num, \"metadata model\" = roc_auc) |> \n#   arrange(split_num)\n# \n# test_metrics_passive <- read_csv(here::here(path_models,\n#                                     \"best_config_v17_kfold_passive.csv\"),\n#                             show_col_types = FALSE) |>\n#   select(split_num, \"passive metadata model\" = roc_auc) |>\n#   arrange(split_num)\n\n\n\ntest_metrics_all <- test_metrics_full |> \n  left_join(test_metrics_baseline, by = c(\"split_num\")) |> \n  # left_join(test_metrics_meta, by = c(\"split_num\")) |>\n  # left_join(test_metrics_passive, by = c(\"split_num\")) |>\n  mutate(fold_num = rep(1:5, 6),\n         repeat_num = c(rep(1, 5), rep(2, 5), rep(3, 5), \n                        rep(4, 5), rep(5, 5), rep(6, 5))) |> \n  select(-split_num) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 30\nColumns: 4\n$ `full model`     <dbl> 0.7211268, 0.7467387, 0.7520620, 0.6333986, 0.4769706…\n$ `baseline model` <dbl> 0.7522946, 0.7764934, 0.7510941, 0.6374951, 0.4399091…\n$ fold_num         <int> 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3,…\n$ repeat_num       <dbl> 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4,…\n```\n\n\n:::\n:::\n\n\n\n\n#### Model evaluation\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| output: false\n\n# Repeated CV (id = repeat, id2 = fold within repeat)\n# with a common variance:  statistic ~ model + (model | id2/id)\nset.seed(101)\npp <- test_metrics_all |> \n  rename(id = fold_num,\n         id2 = repeat_num) |> \n  perf_mod(formula = statistic ~ model + (1 | id2/id),\n         transform = tidyposterior::logit_trans,  # for skewed & bounded AUC\n         iter = 4000, chains = 4, adapt_delta = .99, # increased iteration from 2000 to fix divergence issues\n         family = gaussian, \n)  \n```\n\n::: {.cell-output .cell-output-stdout .hidden}\n\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 6.2e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.62 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 4000 [  0%]  (Warmup)\nChain 1: Iteration:  400 / 4000 [ 10%]  (Warmup)\nChain 1: Iteration:  800 / 4000 [ 20%]  (Warmup)\nChain 1: Iteration: 1200 / 4000 [ 30%]  (Warmup)\nChain 1: Iteration: 1600 / 4000 [ 40%]  (Warmup)\nChain 1: Iteration: 2000 / 4000 [ 50%]  (Warmup)\nChain 1: Iteration: 2001 / 4000 [ 50%]  (Sampling)\nChain 1: Iteration: 2400 / 4000 [ 60%]  (Sampling)\nChain 1: Iteration: 2800 / 4000 [ 70%]  (Sampling)\nChain 1: Iteration: 3200 / 4000 [ 80%]  (Sampling)\nChain 1: Iteration: 3600 / 4000 [ 90%]  (Sampling)\nChain 1: Iteration: 4000 / 4000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 2.733 seconds (Warm-up)\nChain 1:                2.134 seconds (Sampling)\nChain 1:                4.867 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 2.5e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 4000 [  0%]  (Warmup)\nChain 2: Iteration:  400 / 4000 [ 10%]  (Warmup)\nChain 2: Iteration:  800 / 4000 [ 20%]  (Warmup)\nChain 2: Iteration: 1200 / 4000 [ 30%]  (Warmup)\nChain 2: Iteration: 1600 / 4000 [ 40%]  (Warmup)\nChain 2: Iteration: 2000 / 4000 [ 50%]  (Warmup)\nChain 2: Iteration: 2001 / 4000 [ 50%]  (Sampling)\nChain 2: Iteration: 2400 / 4000 [ 60%]  (Sampling)\nChain 2: Iteration: 2800 / 4000 [ 70%]  (Sampling)\nChain 2: Iteration: 3200 / 4000 [ 80%]  (Sampling)\nChain 2: Iteration: 3600 / 4000 [ 90%]  (Sampling)\nChain 2: Iteration: 4000 / 4000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 2.821 seconds (Warm-up)\nChain 2:                3.562 seconds (Sampling)\nChain 2:                6.383 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 2.3e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 4000 [  0%]  (Warmup)\nChain 3: Iteration:  400 / 4000 [ 10%]  (Warmup)\nChain 3: Iteration:  800 / 4000 [ 20%]  (Warmup)\nChain 3: Iteration: 1200 / 4000 [ 30%]  (Warmup)\nChain 3: Iteration: 1600 / 4000 [ 40%]  (Warmup)\nChain 3: Iteration: 2000 / 4000 [ 50%]  (Warmup)\nChain 3: Iteration: 2001 / 4000 [ 50%]  (Sampling)\nChain 3: Iteration: 2400 / 4000 [ 60%]  (Sampling)\nChain 3: Iteration: 2800 / 4000 [ 70%]  (Sampling)\nChain 3: Iteration: 3200 / 4000 [ 80%]  (Sampling)\nChain 3: Iteration: 3600 / 4000 [ 90%]  (Sampling)\nChain 3: Iteration: 4000 / 4000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 2.77 seconds (Warm-up)\nChain 3:                3.3 seconds (Sampling)\nChain 3:                6.07 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 2.4e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.24 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 4000 [  0%]  (Warmup)\nChain 4: Iteration:  400 / 4000 [ 10%]  (Warmup)\nChain 4: Iteration:  800 / 4000 [ 20%]  (Warmup)\nChain 4: Iteration: 1200 / 4000 [ 30%]  (Warmup)\nChain 4: Iteration: 1600 / 4000 [ 40%]  (Warmup)\nChain 4: Iteration: 2000 / 4000 [ 50%]  (Warmup)\nChain 4: Iteration: 2001 / 4000 [ 50%]  (Sampling)\nChain 4: Iteration: 2400 / 4000 [ 60%]  (Sampling)\nChain 4: Iteration: 2800 / 4000 [ 70%]  (Sampling)\nChain 4: Iteration: 3200 / 4000 [ 80%]  (Sampling)\nChain 4: Iteration: 3600 / 4000 [ 90%]  (Sampling)\nChain 4: Iteration: 4000 / 4000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 2.803 seconds (Warm-up)\nChain 4:                1.996 seconds (Sampling)\nChain 4:                4.799 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npp_tidy <- pp |> \n  tidy(seed = 123) \n\nq = c(.025, .5, .975)\npp_perf_tibble <- pp_tidy |> \n  group_by(model) |> \n  summarize(pp_median = quantile(posterior, probs = q[2]),\n            pp_lower = quantile(posterior, probs = q[1]), \n            pp_upper = quantile(posterior, probs = q[3])) |> \n  mutate(model = factor(model, levels = c(\"full model\", \"baseline model\", \"metadata model\", \"passive metadata model\"))) |> \n  arrange(model)\n\npp_perf_tibble |> \n  write_csv(here::here(path_models, \"pp_perf_tibble.csv\"))\n\npp_tidy |> \n  write_csv(here::here(path_models, \"posteriors.csv\"))\n\npp_perf_tibble\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  model          pp_median pp_lower pp_upper\n  <fct>              <dbl>    <dbl>    <dbl>\n1 full model         0.682    0.653    0.711\n2 baseline model     0.686    0.658    0.715\n```\n\n\n:::\n:::\n\n\n\n\n\n### Model Comparison\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nci_baseline <- pp |>\n  contrast_models(list(\"full model\"),\n                  list(\"baseline model\")) |>\n  summary(size = 0) |> \n  mutate(probability = 1 - probability,\n         contrast = \"full model vs. baseline model\")\n\nci_median_baseline <- pp |>\n  contrast_models(list(\"full model\"),\n                  list(\"baseline model\")) |>\n  group_by(contrast) |>\n  summarize(median = quantile(difference, .5)) \n\n\nci_baseline <- ci_baseline |>\n  left_join(ci_median_baseline, by = c(\"contrast\"))\n\nci_baseline |>\n  write_csv(here::here(path_models, \"contrast_baseline.csv\"))\n\nci_baseline\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 10\n  contrast      probability     mean   lower   upper  size pract_neg pract_equiv\n  <chr>               <dbl>    <dbl>   <dbl>   <dbl> <dbl>     <dbl>       <dbl>\n1 full model v…       0.786 -0.00427 -0.0132 0.00467     0        NA          NA\n# ℹ 2 more variables: pract_pos <dbl>, median <dbl>\n```\n\n\n:::\n:::\n",
    "supporting": [
      "ana_bayesian_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}